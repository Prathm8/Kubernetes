----------------------------------- Kubernetes---------------------------------------------

Kubernetes is a container orchestration system that was initially designed by Google to help scale
containerized applications in the cloud. Kubernetes can manage the lifecycle of containers, creating and
destroying them depending on the needs of the application, as well as providing a host of other features.
Kubernetes has become one of the most discussed concepts in cloud-based application development,
and the rise of Kubernetes signals a shift in the way that applications are developed and deployed.
In general, Kubernetes is formed by a cluster of servers, called Nodes, each running Kubernetes agent
processes and communicating with one another. The Master Node contains a collection of processes
called the control plane that helps enact and maintain the desired state of the Kubernetes cluster, while
Worker Nodes are responsible for running the containers that form your applications and services.



## A Kubernetes cluster is composed of two separate planes:

Kubernetes control plane—manages Kubernetes clusters and the workloads running on them. Include components like the API Server, Scheduler, and Controller Manager.
Kubernetes Workernode that can run containerized workloads. Each node is managed by the kubelet, an agent that receives commands from the control plane. --

==============================================================
## Master Node or Control Node compomnents  ##

F
## API Server -------
Provides an API that serves as the front end of a Kubernetes control plane. It is responsible for handling external and internal requests—determining whether a request is valid and then processing it. The API can be accessed via the kubectl command-line interface or other tools like kubeadm, and via REST calls.

## Scheduler :------ 
This component is responsible for scheduling pods on specific nodes according to automated workflows and user defined conditions, which can include resource requests

## etcd :-----
A key-value database that contains data about your cluster state and configuration. Etcd is fault tolerant and distributed.

## Controller:-----
It receives information about the current state of the cluster and objects within it, and sends instructions to move the cluster towards the cluster operator’s desired state. 

====================================================================
## Worker Node Components ##

## kubelet: ----
Each node contains a kubelet, which is a small application that can communicate with the Kubernetes control plane. The kubelet is responsible for ensuring that containers specified in pod configuration are running on a specific node, and manages their lifecycle.. It executes the actions commanded by your control plane

## Kube Proxy :---
All compute nodes contain kube-proxy, a network proxy that facilitates Kubernetes networking services. It handles all network communications outside and inside the cluster, forwarding traffic or replying on the packet filtering layer of the operating system.

## Container Runtime Engine :---
Each node comes with a container runtime engine, which is responsible for running containers. Docker is a popular container runtime engine, but Kubernetes supports other runtimes that are compliant with Open Container Initiative, including CRI-O and rkt.

===============================================================================
##  CORE COmponents ##

#Nodes: ----
Nodes are physical or virtual machines that can run pods as part of a Kubernetes cluster. A cluster can scale up to 5000 nodes. To scale a cluster’s capacity, you can add more nodes.

#POD:--------

Pods—pods are the smallest unit provided by Kubernetes to manage containerized workloads.  A pod typically includes several containers, which together form a functional unit or microservice.

======================================================================================
What is Minikube?
Minikube is a tool that sets up a Kubernetes environment on a local PC or laptop
minikube quickly sets up a local Kubernetes cluster on macOS, Linux, and Windows. We proudly focus on helping application developers and new Kubernetes users.


---Installation Process Minikube ---

curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64

sudo install minikube-linux-amd64 /usr/local/bin/minikube

to start minikube---minikube start --force    #Need docker installation first 
to check status ----minikube status 
to update       --- minikube update-context

What is Kubectl?

kubectl is the Kubernetes-specific command line tool that lets you communicate and control Kubernetes clusters. Whether you're creating, managing, or deleting resources on your Kubernetes platform, kubectl is an essential tool.

----------kubectl Installation-----------
curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl

chmod +x ./kubectl  -----Make the kubectl binary executable

sudo mv ./kubectl /usr/local/bin/kubectl

=============================================================
# EKS cluster Setup Process 

  # Create an IAM Role and attache it to EC2 instance    
   `Note: create IAM user with programmatic access if your bootstrap system is outside of AWS`   
   IAM user should have access to   
   IAM   
   EC2   
   VPC    
   CloudFormation


   #. Setup eksctl   
   a. Download and extract the latest release   
   b. Move the extracted binary to /usr/local/bin   
   c. Test that your eksclt installation was successful   
   ```sh
   curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
   sudo mv /tmp/eksctl /usr/local/bin
   eksctl version


  # Create your cluster and nodes 
   ```sh
   eksctl create cluster --name cluster-name  \
   --region region-name \
   --node-type instance-type \
   --nodes-min 2 \
   --nodes-max 2 \ 
   --zones <AZ-1>,<AZ-2>
   
   example:
   eksctl create cluster --name prathm --region us-east-2 --node-type t2.small 

# after create cluster to update it
 aws eks update-kubeconfig --region <region> --name <cluster name>


 # To delete the EKS clsuter 
    
    
   
   





--------------------------Kubernetes workloads----------------------------------------------
Imperative:

kubectl run pod --image nginx
------------------------- pods ---------------------------------------------------------------

kubect apply -f pod <.yaml>

kubectl get pods

kubectl get pods -o wide    # to see the 

kubectl delete pod <pod name>

kubectl describe pods <name of the pod>  # to know more details about pod 

kubectl exec <pod-name>  -it -- /bin/sh 


---Pod.yaml---


apiVersion: v1
kind: Pod
metadata:
  name: myapp
  labels:
      app: webapp
      type: front-end
spec:
  containers:
  - name: nginx-container 
    image: nginx




====================================================================
#Kuberentes Service#:

Kubernetes, a Service is a method for exposing a network application that is running as one or more Pods in your cluster.

git hub link for dervice files : https://github.com/CloudTechDevOps/Kubernetes/tree/main/day-3-services
--Types:

# ClusterIP : This is the default type for service in Kubernetes.

As indicated by its name, this is just an address that can be used inside the cluster.

# NodePort: A NodePort differs from the ClusterIP in the sense that it exposes a port in each Node.

When a NodePort is created, kube-proxy exposes a port in the range 30000-32767:

# LoadBlancer :

This service type creates load balancers in various Cloud providers like AWS, GCP, Azure, etc., to expose our application to the Internet.



##Kubernetes has several port configurations for Services:

#Port: the port on which the service is exposed. Other pods can communicate with it via this port.

#TargetPort: the actual port on which your container is deployed. The service sends requests to this port and the pod container must listen to the same port.

#NodePort: exposes a service externally to the cluster. So the application can be accessed via this port externally. By default, it’s automatically assigned during deployment.

========================================================================================================


## Horizonal Pod Auto Scaling ##


In Kubernetes, a HorizontalPodAutoscaler automatically updates a workload resource (such as a Deployment or StatefulSet), with the aim of automatically scaling the workload to match demand.

Horizontal scaling means that the response to increased load is to deploy more Pods. This is different from vertical scaling, which for Kubernetes would mean assigning more resources (for example: memory or CPU) to the Pods that are already running for the workload.

If the load decreases, and the number of Pods is above the configured minimum, the HorizontalPodAutoscaler instructs the workload resource (the Deployment, StatefulSet, or other similar resource) to scale back down.
git hub link for hpa files : "https://github.com/CloudTechDevOps/Kubernetes/tree/main/day-4-horizonalScaling"

# Metric Server deployment ##

The Kubernetes Metrics Server is an aggregator of resource usage data in your cluster, and it isn't deployed by default in Amazon EKS clusters.

we need to deploy by following process 

#Deploy the Metrics Server with the following command:

kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml


#Verify that the metrics-server deployment is running the desired number of Pods with the following command.
 
kubectl get deployment metrics-server -n kube-system

kubectl top pod # to see pod load

kubectl top node # to see node load 

-----------------------------------ingress-------------------------

What is an Ingress?
In Kubernetes, an Ingress is an object that allows access to your Kubernetes services from outside the Kubernetes cluster. You configure access by creating a collection of rules that define which inbound connections reach which services.

kubectl create namespace ingress-nginx # create name space for ingress-nginx

kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.1/deploy/static/provider/cloud/deploy.yaml     ----to install ingress controller yaml 


Create Below deployment file git hub link https://github.com/CloudTechDevOps/Kubernetes/tree/main/day-5-ingress

create deployemnt file for path-1

create deployment file for path-2

create ingress reosurce file 

Note:
after deploy the above files just run below command 
kubectl get ingress
we are able to seec load blancer link and acces by giving path along 


#Enable top Command-
   kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
   kubectl get deployment metrics-server -n kube-system
